{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b1b0f5-8b85-4b73-b467-bc77e244582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glypy\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "monosaccharides = glypy.monosaccharides\n",
    "\n",
    "glcnac1 = monosaccharides[\"GlcNAc\"]\n",
    "glcnac2 = monosaccharides[\"GlcNAc\"]\n",
    "\n",
    "glcnac1.add_monosaccharide(glcnac2, position=4, child_position=1)\n",
    "bdman = monosaccharides[\"bdMan\"]\n",
    "glcnac2.add_monosaccharide(bdman, position=4, child_position=1)\n",
    "adman1 = monosaccharides[\"adMan\"]\n",
    "bdman.add_monosaccharide(adman1, position=3, child_position=1)\n",
    "adman2 = monosaccharides[\"adMan\"]\n",
    "bdman.add_monosaccharide(adman2, position=6, child_position=1)\n",
    "\n",
    "n_linked_core = glypy.Glycan(root=glcnac1)\n",
    "n_linked_core.reindex()\n",
    "n_linked_core.canonicalize()\n",
    "print(n_linked_core)\n",
    "print(n_linked_core.mass())\n",
    "print(n_linked_core.total_composition())\n",
    "\n",
    "for link, linkage in n_linked_core.iterlinks():\n",
    "    print(\"linkage\" , linkage.parent.id, linkage.child.id)\n",
    "    \n",
    "for node in n_linked_core.iternodes():\n",
    "    print(node.id, node.serialize(\"IUPAC\"))\n",
    "\n",
    "\n",
    "def get_saccharide_saccharide_link_properties(parent_node, child_node, link):\n",
    "    attributes = {\"parent_anomer\" : str(parent_node.anomer),\n",
    "                  \"child_anomer\" : str(child_node.anomer),\n",
    "                  \"linkage_type\" : \"saccharide\",\n",
    "                  \"constant\" : \"constant\"}\n",
    "    return attributes\n",
    "\n",
    "def get_saccharide_substituent_link_properties(saccharide, substituent, link):\n",
    "    attributes = {\"parent_position\" : link.parent_position,\n",
    "              \"child_position\" : link.child_position,\n",
    "              \"child_anomer\" : str(saccharide.anomer),\n",
    "              \"linkage_type\" : \"substituent\",\n",
    "              \"constant\" : \"constant\"}\n",
    "    return attributes\n",
    "    \n",
    "\n",
    "def nx_glycan_graph(glypy_glycan):\n",
    "    glypy_glycan = glypy_glycan.canonicalize()\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    # Iterate over the glycan structure\n",
    "    for node in glypy_glycan.iternodes():\n",
    "        # Add each monosaccharide as a node\n",
    "        for idx, substituent in node.substituents():\n",
    "            G.add_node(substituent.id, composition = substituent.composition, node_type = \"substituent\", constant = \"constant\")\n",
    "        G.add_node(node.id, composition = node.serialize(name='IUPAC'), node_type = \"saccharide\", constant = \"constant\")\n",
    "\n",
    "\n",
    "    for link, linkage in glypy_glycan.iterlinks(substituents = True):\n",
    "        parent = linkage.parent\n",
    "        child = linkage.child\n",
    "        if isinstance(parent,glypy.structure.monosaccharide.Monosaccharide) and isinstance(child,glypy.structure.monosaccharide.Monosaccharide):\n",
    "            attributes = get_saccharide_saccharide_link_properties(parent, child, linkage)\n",
    "        elif isinstance(parent,glypy.structure.substituent.Substituent):\n",
    "            attributes = get_saccharide_substituent_link_properties(child, parent, linkage)\n",
    "        elif isinstance(child,glypy.structure.substituent.Substituent):\n",
    "            attributes = get_saccharide_substituent_link_properties(parent, child, linkage)\n",
    "        \n",
    "        G.add_edge(linkage.parent.id, linkage.child.id, **attributes)\n",
    "\n",
    "        \n",
    "    return(G)\n",
    "    \n",
    "\n",
    "g = nx_glycan_graph(n_linked_core)    \n",
    "# Get labels from the graph\n",
    "labels = nx.get_node_attributes(g, 'composition')\n",
    "\n",
    "# Draw the graph with labels\n",
    "pos = nx.spring_layout(g)\n",
    "colors = []\n",
    "for node in g.nodes:\n",
    "    if g.nodes[node]['node_type'] == 'saccharide':\n",
    "        colors.append('red')\n",
    "    elif g.nodes[node]['node_type'] == 'substituent':\n",
    "        colors.append('blue')\n",
    "    else:\n",
    "        colors.append('green')\n",
    "\n",
    "# Draw the graph with the color map\n",
    "nx.draw(g, node_color=colors, with_labels=True)\n",
    "\n",
    "# Draw edge labels\n",
    "edge_labels = nx.get_edge_attributes(g, 'constant')\n",
    "nx.draw_networkx_edge_labels(g, pos, edge_labels=edge_labels)\n",
    "\n",
    "# Show the graph\n",
    "plt.show()\n",
    "\n",
    "glycosmos_glycans = pd.read_csv(\"glycosmos_glycans_wurcs.csv\")\n",
    "\n",
    "from glypy.io import wurcs\n",
    "wurcs_struct = wurcs.loads(glycosmos_glycans.loc[0].WURCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaab130c-f152-493b-9818-108dd737cc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "glycosmos_glycans_unique = glycosmos_glycans.drop_duplicates(subset=[\"WURCS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9690e040-d336-4904-8f8b-0b40c4d03c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import quote\n",
    "import json\n",
    "\n",
    "# create empty lists to hold the GlyTouCan IDs and GlycoCT strings\n",
    "glytoucan_ids = []\n",
    "glycoct_strings = []\n",
    "url = \"https://api.glycosmos.org/glycanformatconverter/2.8.2/wurcs2glycoct\"\n",
    "\n",
    "#glycoct_strings = []  # Create a new list to hold the GlycoCT strings\n",
    "\n",
    "with Progress() as progress: #transient=True\n",
    "\n",
    "    convert_wurcs = progress.add_task(\"[red]Converting WURCS strings to GlycoCT...\", total=len(range(0, len(glycosmos_glycans_unique['WURCS']), n)) +1)  \n",
    "    \n",
    "    while not progress.finished:\n",
    "        try:\n",
    "            with open('glycoct_strings.pkl', 'rb') as f:\n",
    "                responses = pickle.load(f)\n",
    "            progress.update(convert_wurcs, advance=len(range(0, len(glycosmos_glycans_unique['WURCS']), n)) +1)\n",
    "            time.sleep(0.1)\n",
    "        except:\n",
    "            print(\"in the exception\")\n",
    "            for wurcs_string in glycosmos_glycans_unique['WURCS']:\n",
    "                data = {\"input\":wurcs_string}\n",
    "                headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "                response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "                if response.status_code == 200:\n",
    "                    response_data = response.json()\n",
    "                    if 'message' in response_data and response_data['message'] == 'Returned null.':\n",
    "                        #print(\"The server returned null. It may not have found the data you were looking for.\")\n",
    "                        glycoct_strings.append(None)\n",
    "                    else:\n",
    "                        glycoct_strings.append(response_data['GlycoCT'])\n",
    "\n",
    "                else:\n",
    "                    print(f\"Request failed with status code {response.status_code}\")\n",
    "                    glycoct_strings.append(None)  # Append None or some default value if the request failed\n",
    "                progress.update(convert_wurcs ,advance = 1)\n",
    "\n",
    "            with open('glycoct_strings.pkl', 'wb') as f:\n",
    "                pickle.dump(glycoct_strings, f)\n",
    "            \n",
    "# After the loop, add the list as a new column to your DataFrame\n",
    "glycosmos_glycans_unique['GlycoCT'] = glycoct_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb49c48a-ff3f-4c2a-91d0-2c239a3d12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "glycoct_strings = [\"\"\"RES\n",
    "1b:b-dglc-HEX-1:5\n",
    "2s:n-acetyl\n",
    "3b:b-dglc-HEX-1:5\n",
    "4s:n-acetyl\n",
    "LIN\n",
    "1:1d(2+1)2n\n",
    "2:1o(4+1)3d\n",
    "3:3d(2+1)4n\"\"\",\n",
    "                  \"\"\"RES\n",
    "1b:b-dglc-HEX-1:5\n",
    "2s:n-acetyl\n",
    "3b:b-dglc-HEX-1:5\n",
    "4s:n-acetyl\n",
    "5b:b-dman-HEX-1:5\n",
    "6b:a-dman-HEX-1:5\n",
    "7b:b-dglc-HEX-1:5\n",
    "8s:n-acetyl\n",
    "9b:a-dgal-HEX-1:5\n",
    "10s:n-acetyl\n",
    "11s:sulfate\n",
    "12b:b-lgal-HEX-1:5|6:d\n",
    "LIN\n",
    "1:1d(2+1)2n\n",
    "2:1o(4+1)3d\n",
    "3:3d(2+1)4n\n",
    "4:3o(4+1)5d\n",
    "5:5o(3+1)6d\n",
    "6:6o(4+1)7d\n",
    "7:7d(2+1)8n\n",
    "8:7o(4+1)9d\n",
    "9:9d(2+1)10n\n",
    "10:9o(4+1)11n\n",
    "11:1o(6+1)12d\n",
    "\"\"\",\n",
    "              \"\"\"RES\n",
    "1b:b-dglc-HEX-1:5\n",
    "2s:n-acetyl\n",
    "3b:b-dglc-HEX-1:5\n",
    "4s:n-acetyl\n",
    "5b:b-dman-HEX-1:5\n",
    "6b:a-dman-HEX-1:5\n",
    "7b:a-dman-HEX-1:5\n",
    "8b:a-dman-HEX-1:5\n",
    "LIN\n",
    "1:1d(2+1)2n\n",
    "2:1o(4+1)3d\n",
    "3:3d(2+1)4n\n",
    "4:3o(4+1)5d\n",
    "5:5o(3+1)6d\n",
    "6:6o(2+1)7d\n",
    "7:5o(6+1)8d\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c1ed79-fe7e-424e-9560-772f93c4b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import quote\n",
    "import json\n",
    "\n",
    "# create empty lists to hold the GlyTouCan IDs and GlycoCT strings\n",
    "\n",
    "url = \"http://csdb.glycoscience.ru/database/core/convert_api.php\"\n",
    "csdb_strings = []  # Create a new list to hold the GlycoCT strings\n",
    "\n",
    "for glycoct_string in glycoct_strings:\n",
    "    data = {\"glycoct\":glycoct_string}\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "    response = requests.get(f\"{url}?glycoct={quote(glycoct_string)}\")\n",
    "    if response.status_code == 200:\n",
    "        response_data = response.text.replace(\"<pre>\", \"\")  # Remove the <pre> tag\n",
    "        lines = response_data.split(\"\\n\")  # Split into lines\n",
    "        \n",
    "        for line in lines:\n",
    "            if line.startswith(\"CSDB Linear:\"):\n",
    "                csdb_linear = line.replace(\"CSDB Linear:\", \"\").strip()  # Extract the CSDB Linear string\n",
    "                csdb_strings.append(csdb_linear)  # Append the string to the list\n",
    "                break\n",
    "            \n",
    "    else:\n",
    "        print(f\"Request failed with status code {response.status_code}\")\n",
    "\n",
    "print(csdb_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed01495-b98c-4df6-9bdd-c6246004d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(f\"http://csdb.glycoscience.ru/database/core/convert_api.php?csdb={quote(csdb_strings[0])}&format=smiles\")\n",
    "response2 = requests.get(f\"http://csdb.glycoscience.ru/database/core/convert_api.php?csdb={quote(csdb_strings[1])}&format=smiles\")\n",
    "response3 = requests.get(f\"http://csdb.glycoscience.ru/database/core/convert_api.php?csdb={quote(csdb_strings[2])}&format=smiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adb523f-8120-492f-a1b6-659873f8e18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"smiles=(.*?)\\'\"\n",
    "\n",
    "match = re.findall(pattern, response.text)\n",
    "match2 = re.findall(pattern, response2.text)\n",
    "match3 = re.findall(pattern, response3.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe6d9f8-2d45-4339-812d-bffc55c6a5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sugar1 = Chem.MolFromSmiles(urllib.parse.unquote(match[0]))\n",
    "sugar2 = Chem.MolFromSmiles(urllib.parse.unquote(match2[0]))\n",
    "sugar3 = Chem.MolFromSmiles(urllib.parse.unquote(match3[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97d4618-14b7-41d4-b73e-acede439d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_data = response.text.replace(\"<pre>\", \"\")  # Remove the <pre> tag\n",
    "lines = response_data.split(\"\\n\")  # Split into lines\n",
    "\n",
    "for line in lines:\n",
    "    if line.startswith(\"CSDB Linear:\"):\n",
    "        csdb_linear = line.replace(\"CSDB Linear:\", \"\").strip()  # Extract the CSDB Linear string\n",
    "        csdb_strings.append(csdb_linear)  # Append the string to the list\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3aca28-361e-4c03-b43c-ce1df94f8052",
   "metadata": {},
   "outputs": [],
   "source": [
    "csdb_strings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cf74ca-6054-403f-8256-b197706f57f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "monosaccharides = glypy.monosaccharides\n",
    "\n",
    "glcnac1 = monosaccharides[\"GlcNAc\"]\n",
    "glcnac2 = monosaccharides[\"GlcNAc\"]\n",
    "glcnac3 = monosaccharides[\"GlcNAc\"]\n",
    "\n",
    "glcnac1.add_monosaccharide(glcnac2, position=4, child_position=1)\n",
    "bdman = monosaccharides[\"bdMan\"]\n",
    "glcnac2.add_monosaccharide(bdman, position=4, child_position=1)\n",
    "adman1 = monosaccharides[\"adMan\"]\n",
    "bdman.add_monosaccharide(adman1, position=3, child_position=1)\n",
    "adman2 = monosaccharides[\"adMan\"]\n",
    "bdman.add_monosaccharide(adman2, position=6, child_position=1)\n",
    "\n",
    "n_linked_core = glypy.Glycan(root=glcnac1)\n",
    "n_linked_core.reindex()\n",
    "n_linked_core.canonicalize()\n",
    "\n",
    "g1 = nx_glycan_graph(n_linked_core)\n",
    "\n",
    "monosaccharides = glypy.monosaccharides\n",
    "\n",
    "glcnac1 = monosaccharides[\"GlcNAc\"]\n",
    "glcnac2 = monosaccharides[\"GlcNAc\"]\n",
    "glcnac3 = monosaccharides[\"GlcNAc\"]\n",
    "bdman = monosaccharides[\"bdMan\"]\n",
    "adman1 = monosaccharides[\"adMan\"]\n",
    "adman2 = monosaccharides[\"adMan\"]\n",
    "\n",
    "glcnac1.add_monosaccharide(glcnac2, position=4, child_position=1)\n",
    "glcnac1.add_monosaccharide(glcnac3, position=6, child_position=1)\n",
    "glcnac2.add_monosaccharide(bdman, position=4, child_position=1)\n",
    "bdman.add_monosaccharide(adman1, position=3, child_position=1)\n",
    "bdman.add_monosaccharide(adman2, position=6, child_position=1)\n",
    "\n",
    "n_linked_core = glypy.Glycan(root=glcnac1)\n",
    "n_linked_core.reindex()\n",
    "n_linked_core.canonicalize()\n",
    "\n",
    "from glypy.io import glycoct\n",
    "\n",
    "\n",
    "g2 = nx_glycan_graph(n_linked_core)\n",
    "\n",
    "# Create a mannose monosaccharide\n",
    "mannose = glypy.monosaccharides.Man\n",
    "\n",
    "# Add mannose to the glycan at position 3 of the root\n",
    "#target_monosaccharide = list(glypy_g1.root.children.values())[0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a6df2a-1b91-4058-b180-e0b5619aa670",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "nx.draw(g1, with_labels = True)\n",
    "nx.draw(g2, with_labels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e456346d-4a5c-4064-895e-caeb2be7a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx.algorithms.isomorphism\n",
    "\n",
    "def get_parity_score_sugar(graph1, graph2):\n",
    "    \n",
    "    matcher = nx.isomorphism.ISMAGS(graph1, graph2)\n",
    "    largest_common_subgraph = list(matcher.largest_common_subgraph())\n",
    "    mcs = {}\n",
    "    current_best_matches = 0\n",
    "    for match in largest_common_subgraph:\n",
    "        exact_matches = 0\n",
    "        for graph1_node, graph2_node in match.items():\n",
    "            graph1_node_attributes = graph1.nodes[graph1_node]\n",
    "            graph2_node_attributes = graph2.nodes[graph2_node]\n",
    "            if graph1_node_attributes == graph2_node_attributes:\n",
    "                exact_matches += 1\n",
    "        print(exact_matches)\n",
    "        print(\"_____\")\n",
    "        if exact_matches >= current_best_matches:\n",
    "            current_best_matches = exact_matches\n",
    "            mcs = match\n",
    "    # check if there's a subgraph isomorphic\n",
    "    return match\n",
    "\n",
    "get_parity_score_sugar(g2,g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a557ef93-4549-4614-97e8-d22a6d7465eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_match(node1, node2):\n",
    "    return node1['constant'] == node2['constant']\n",
    "\n",
    "def edge_match(edge1, edge2):\n",
    "    return edge1['linkage'] == edge2['constant']\n",
    "\n",
    "GM = networkx.algorithms.isomorphism.GraphMatcher(g2, g1, node_match=node_match, edge_match=edge_match)\n",
    "\n",
    "for subgraph in GM.subgraph_isomorphisms_iter():\n",
    "    print(subgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01778e6-78f1-45bf-a57f-2e864725046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from typing import List\n",
    "from rich.progress import Progress, track\n",
    "from rich.console import Console\n",
    "\n",
    "import pandas as pd\n",
    "from Bio.PDB import MMCIFParser, PDBList\n",
    "import os\n",
    "import time\n",
    "\n",
    "import gzip\n",
    "from multiprocessing import Pool, Manager\n",
    "from functools import partial\n",
    "from wurcs_access import get_wurcs_single\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pickle\n",
    "\n",
    "import requests\n",
    "import os\n",
    "from typing import List\n",
    "from rich.progress import Progress, track\n",
    "from rich.console import Console\n",
    "\n",
    "import gzip\n",
    "from multiprocessing import Pool, Manager\n",
    "from functools import partial\n",
    "\n",
    "def download_pdb_files(pdb_ids: List[str], outdir='.', file_format='cif'):\n",
    "    \"\"\"\n",
    "    Downloads PDB files in the specified format for a list of PDB ids.\n",
    "\n",
    "    This function is adapted from the 'batch_download.sh' script provided by RCSB PDB.\n",
    "\n",
    "    Args:\n",
    "        pdb_ids: A list of PDB ids.\n",
    "        outdir: The directory to save the downloaded files. Default is the current directory.\n",
    "        file_format: The file format to download. Default is 'cif'.\n",
    "        \n",
    "    \"\"\"\n",
    "    base_url = \"https://files.rcsb.org/download\"\n",
    "    console = Console()\n",
    "    if not os.path.exists(outdir):\n",
    "        os.makedirs(outdir)\n",
    "    download_pdbs = []\n",
    "    successful_pdbs = []\n",
    "    for pdb_id in pdb_ids:\n",
    "        file_name = f\"{pdb_id}.{file_format}\"\n",
    "        file_path = os.path.join(outdir, file_name)\n",
    "        if not os.path.isfile(file_path):\n",
    "            download_pdbs.append(pdb_id)\n",
    "        else:\n",
    "            successful_pdbs.append(pdb_id)\n",
    "    console.log(f\"Downloading {len(download_pdbs)} PDB files in {file_format} format.\")\n",
    "    failed_pdbs = []\n",
    "    if len(download_pdbs) > 0:\n",
    "        for pdb_id in track(download_pdbs, description='[green]Downloading PDBs...'):\n",
    "\n",
    "            file_name = f\"{pdb_id}.{file_format}.gz\"\n",
    "            file_path = os.path.join(outdir, file_name)\n",
    "            url = f\"{base_url}/{file_name}\"\n",
    "            response = requests.get(url)\n",
    "            if not os.path.isfile(file_path):\n",
    "                response = requests.get(url)\n",
    "                if response.status_code == 200:\n",
    "                    with open(os.path.join(outdir, file_name), 'wb') as f:\n",
    "                        f.write(response.content)\n",
    "                    successful_pdbs.append(pdb_id)\n",
    "                else:\n",
    "                    console.log(f\"Failed to download {pdb_id}\")\n",
    "                    failed_pdbs.append(pdb_id)\n",
    "    return successful_pdbs, failed_pdbs\n",
    "\n",
    "def get_wurcs(pdb_entities, directory='.'):\n",
    "    # create a Manager object\n",
    "    with Manager() as manager:\n",
    "        # create a Manager dictionary for WURCS strings and failed entities\n",
    "        wurcs_dict = manager.dict()\n",
    "        failed_entities = manager.list()\n",
    "        \n",
    "        # partial function for pool\n",
    "        func = partial(get_wurcs_single, directory=directory, wurcs_dict=wurcs_dict, failed_entities=failed_entities)\n",
    "        \n",
    "        # create a Pool of processes\n",
    "        with Pool(processes = 8) as pool:\n",
    "            # apply the function to each PDB entity\n",
    "            max_count = len(pdb_entities)\n",
    "            with tqdm(total=max_count) as pbar:\n",
    "                for i, _ in enumerate(pool.imap_unordered(func, pdb_entities)):\n",
    "                    pbar.update()\n",
    "\n",
    "        # convert the Manager dict and list back to regular dict and list\n",
    "        return dict(wurcs_dict), list(failed_entities)\n",
    "\n",
    "\n",
    "# read the CSV file\n",
    "sugar_uniqids = pd.read_csv('sugar_uniqids.csv')\n",
    "\n",
    "pdb_ids = []\n",
    "for pdb_entity in sugar_uniqids['UniqID'].tolist():\n",
    "    pdb_id, entity_id = pdb_entity.split('_')\n",
    "    pdb_ids.append(pdb_id)\n",
    "pdb_ids = list(set(pdb_ids))\n",
    "\n",
    "successful_pdbs, failed_pdbs = download_pdb_files(pdb_ids, outdir='./mmcif_files', file_format='cif')\n",
    "\n",
    "successful_pdb_entities = []\n",
    "for pdb_entity in sugar_uniqids['UniqID'].tolist():\n",
    "    pdb_id, entity_id = pdb_entity.split('_')\n",
    "    if pdb_id in successful_pdbs:\n",
    "        successful_pdb_entities.append(pdb_entity)\n",
    "    \n",
    "try:\n",
    "    with open('sugar_uniqid_wurcs.pkl', 'rb') as f:\n",
    "        wurcs_dict = pickle.load(f)\n",
    "    with open('sugar_uniqid_missing_wurcs.pkl', 'rb') as f:\n",
    "        failed_entities = pickle.load(f)\n",
    "except:\n",
    "    wurcs_dict, failed_entities = get_wurcs(successful_pdb_entities, directory='./mmcif_files')\n",
    "    with open('sugar_uniqid_wurcs.pkl', 'wb') as f:\n",
    "        pickle.dump(wurcs_dict, f)\n",
    "    with open('sugar_uniqid_missing_wurcs.pkl', 'wb') as f:\n",
    "        pickle.dump(failed_entities, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535ba1da-75e0-4f9a-a899-158d3aad00a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "sparql = SPARQLWrapper(\"https://ts.glytoucan.org/sparql\")\n",
    "sparql.setQuery(\"\"\"\n",
    "    PREFIX glycan: <http://purl.jp/bio/12/glyco/glycan#>\n",
    "    PREFIX glytoucan:  <http://www.glytoucan.org/glyco/owl/glytoucan#>\n",
    "\n",
    "    SELECT (COUNT(DISTINCT ?Saccharide) as ?count)\n",
    "    FROM <http://rdf.glytoucan.org/core>\n",
    "    FROM <http://rdf.glytoucan.org/sequence/wurcs>\n",
    "    WHERE {\n",
    "        ?Saccharide glytoucan:has_primary_id ?PrimaryId .\n",
    "        ?Saccharide glycan:has_glycosequence ?GlycoSequence .\n",
    "        ?GlycoSequence glycan:has_sequence ?Sequence .\n",
    "        ?GlycoSequence glycan:in_carbohydrate_format glycan:carbohydrate_format_wurcs.\n",
    "    }\n",
    "\"\"\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "\n",
    "# Access the count result\n",
    "count = int(results['results']['bindings'][0]['count']['value'])\n",
    "\n",
    "print(count)\n",
    "\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "# Specify the SPARQL endpoint\n",
    "sparql = SPARQLWrapper(\"https://ts.glytoucan.org/sparql\")\n",
    "# initial offset\n",
    "offset = 0\n",
    "# limit for each chunk\n",
    "limit = 10000\n",
    "glycans = []\n",
    "\n",
    "\n",
    "while not progress.finished:\n",
    "    try:\n",
    "        with open('glytoucan_records.pkl', 'rb') as f:\n",
    "            responses = pickle.load(f)\n",
    "        progress.update(download_glycans, advance=count)\n",
    "    except:\n",
    "        while True:\n",
    "            # Define the query\n",
    "            sparql.setQuery(f\"\"\"\n",
    "                PREFIX glycan: <http://purl.jp/bio/12/glyco/glycan#>\n",
    "                PREFIX glytoucan:  <http://www.glytoucan.org/glyco/owl/glytoucan#>\n",
    "\n",
    "                SELECT DISTINCT ?Saccharide ?PrimaryId ?Sequence\n",
    "                FROM <http://rdf.glytoucan.org/core>\n",
    "                FROM <http://rdf.glytoucan.org/sequence/wurcs>\n",
    "                WHERE {{\n",
    "                    ?Saccharide glytoucan:has_primary_id ?PrimaryId .\n",
    "                    ?Saccharide glycan:has_glycosequence ?GlycoSequence .\n",
    "                    ?GlycoSequence glycan:has_sequence ?Sequence .\n",
    "                    ?GlycoSequence glycan:in_carbohydrate_format glycan:carbohydrate_format_wurcs.\n",
    "                }}\n",
    "                ORDER BY ?PrimaryId\n",
    "\n",
    "            \"\"\") #LIMIT {limit} OFFSET {offset}\n",
    "\n",
    "            # Specify the return format\n",
    "            sparql.setReturnFormat(JSON)\n",
    "\n",
    "            # Execute the query and convert to Python dictionary\n",
    "            result = sparql.query()\n",
    "            # Print the raw response\n",
    "            print(result.response.read())\n",
    "            results = sparql.query().convert()\n",
    "\n",
    "            # Extract the results\n",
    "            bindings = results[\"results\"][\"bindings\"]\n",
    "\n",
    "            parsed_records = [{'Saccharide': record['Saccharide']['value'], \n",
    "                               'PrimaryId': record['PrimaryId']['value'], \n",
    "                               'Sequence': record['Sequence']['value']} \n",
    "                              for record in bindings]\n",
    "\n",
    "            glycans.extend(parsed_records)\n",
    "\n",
    "            # If the number of results is less than the limit, we've reached the end\n",
    "            if len(bindings) < limit:\n",
    "                break\n",
    "\n",
    "            # Increment the offset for the next chunk\n",
    "            offset += limit\n",
    "            progress.update(download_glycans, advance=len(bindings))\n",
    "\n",
    "from py2neo import Graph, Node, Relationship\n",
    "graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"test123\"))  # replace \"your_password\" with the password you set\n",
    "\n",
    "# Open the KCF file\n",
    "with open(\"G10518.kcf\") as f:\n",
    "    nodes = {}\n",
    "    edges = []\n",
    "    mode = None  # Initialize the variable mode\n",
    "    for line in f:\n",
    "        print(line)\n",
    "        if line.startswith(\"ENTRY\"):\n",
    "            mode = \"entry\"\n",
    "            continue\n",
    "        elif line.startswith(\"NODE\"):\n",
    "            mode = \"node\"\n",
    "            continue\n",
    "        elif line.startswith(\"EDGE\"):\n",
    "            mode = \"edge\"\n",
    "            continue\n",
    "        elif line.startswith(\"///\"):\n",
    "            mode = None\n",
    "        if mode == \"node\":\n",
    "            parts = line.strip().split()\n",
    "            node_id = int(parts[0])\n",
    "            node_label = parts[1]\n",
    "            node = Node(node_label)\n",
    "            nodes[node_id] = node\n",
    "            graph.create(node)\n",
    "            print(\"created node\")\n",
    "        elif mode == \"edge\":\n",
    "            parts = line.strip().split()\n",
    "            edge_start = int(parts[1])\n",
    "            edge_end = int(parts[2])\n",
    "            edge = Relationship(nodes[edge_start], \"CONNECTS\", nodes[edge_end])\n",
    "            edges.append(edge)\n",
    "            graph.create(edge)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cognate_ligand_project]",
   "language": "python",
   "name": "conda-env-cognate_ligand_project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
